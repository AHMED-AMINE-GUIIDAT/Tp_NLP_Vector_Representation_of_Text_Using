{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Vector_Representation_of_Text_Using.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOcLx/yuJXrTftL8sanQfVB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AHMED-AMINE-GUIIDAT/Tp_NLP_Vector_Representation_of_Text_Using/blob/main/NLP_Vector_Representation_of_Text_Using.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYGPbDRlJujZ"
      },
      "source": [
        "## **Vector Representation of Text Using**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K88sBRSbJanW",
        "outputId": "8f177f85-95bb-4eeb-e50f-fbb503c12379"
      },
      "source": [
        "dataset = [        \n",
        "\"\"\"Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely\n",
        "the beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from\n",
        "the Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowed rational\n",
        "numbers, irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new\n",
        "development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the\n",
        "subject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a\n",
        "way which had not happened before.\"\"\",\n",
        "\n",
        " \"\"\"ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي  وهي بدايات الجبر،ومن المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن\n",
        "المفهوم اليوناني للرياضيات التي هي في جوهرها  هندسة، الجبركان نظرية موحدة تتحيح الأعداد الكسرية و الأعداد اللا كسرية ، والمقادير الهندسية و غيرها ، أن تتعامل على أنها أجسام جبرية، و أعطت الرياضيات ككل مسارا جديدًا للتطوربمفهوم \n",
        " أوسع بكثير من الذي كان موجودًا من قبل ، وقدم وسيلة للتنمية في هذا الموضوع مستقبلا .و جانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها \n",
        "بطريقة  لم تحدث من قبل.\"\"\"\n",
        "]\n",
        "\n",
        "print(dataset)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely\\nthe beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from\\nthe Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowed rational\\nnumbers, irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new\\ndevelopment path so much broader in concept to that which had existed before, and provided a vehicle for future development of the\\nsubject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a\\nway which had not happened before.', 'ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي  وهي بدايات الجبر،ومن المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن\\nالمفهوم اليوناني للرياضيات التي هي في جوهرها  هندسة، الجبركان نظرية موحدة تتحيح الأعداد الكسرية و الأعداد اللا كسرية ، والمقادير الهندسية و غيرها ، أن تتعامل على أنها أجسام جبرية، و أعطت الرياضيات ككل مسارا جديدًا للتطوربمفهوم \\n أوسع بكثير من الذي كان موجودًا من قبل ، وقدم وسيلة للتنمية في هذا الموضوع مستقبلا .و جانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها \\nبطريقة  لم تحدث من قبل.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8YZl9HXD9pO",
        "outputId": "a9371364-a066-49f0-a8e7-604a796fdd9d"
      },
      "source": [
        "pip install gensim"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zaXy70FKK1n"
      },
      "source": [
        "**data processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0D6VE11KN_I",
        "outputId": "dd4e1c2f-cbd4-4a45-8e47-e8d3f9679d50"
      },
      "source": [
        "import string\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ''' + string.punctuation  \n",
        "\n",
        "def delete_punctuations(sentence):\n",
        "  sentence = sentence.lower()\n",
        "  my_clean_sentence = ''.join([item for item in sentence if item not in punctuations ])\n",
        "  return my_clean_sentence\n",
        "  \n",
        "def sentence_tokenize(text):\n",
        "  return word_tokenize(text)\n",
        "  \n",
        "tokenized_list = sentence_tokenize(delete_punctuations(dataset[0]))\n",
        "print(tokenized_list)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['perhaps', 'one', 'of', 'the', 'most', 'significant', 'advances', 'made', 'by', 'arabic', 'mathematics', 'began', 'at', 'this', 'time', 'with', 'the', 'work', 'of', 'alkhwarizmi', 'namely', 'the', 'beginnings', 'of', 'algebra', 'it', 'is', 'important', 'to', 'understand', 'just', 'how', 'significant', 'this', 'new', 'idea', 'was', 'it', 'was', 'a', 'revolutionary', 'move', 'away', 'from', 'the', 'greek', 'concept', 'of', 'mathematics', 'which', 'was', 'essentially', 'geometry', 'algebra', 'was', 'a', 'unifying', 'theory', 'which', 'allowed', 'rational', 'numbers', 'irrational', 'numbers', 'geometrical', 'magnitudes', 'etc', 'to', 'all', 'be', 'treated', 'as', 'algebraic', 'objects', 'it', 'gave', 'mathematics', 'a', 'whole', 'new', 'development', 'path', 'so', 'much', 'broader', 'in', 'concept', 'to', 'that', 'which', 'had', 'existed', 'before', 'and', 'provided', 'a', 'vehicle', 'for', 'future', 'development', 'of', 'the', 'subject', 'another', 'important', 'aspect', 'of', 'the', 'introduction', 'of', 'algebraic', 'ideas', 'was', 'that', 'it', 'allowed', 'mathematics', 'to', 'be', 'applied', 'to', 'itself', 'in', 'a', 'way', 'which', 'had', 'not', 'happened', 'before']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJqZMxVbK5dH"
      },
      "source": [
        "**Model group Word2vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23ypJgjVK-9P"
      },
      "source": [
        "from gensim.models import Word2Vec,keyedvectors"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylUAQhwELEU1",
        "outputId": "425d2d50-8f4a-4236-901c-a2f9e89b35c4"
      },
      "source": [
        "model = Word2Vec([tokenized_list] , min_count=1, size=32)\n",
        "model.most_similar(\"important\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('objects', 0.4286957383155823),\n",
              " ('essentially', 0.3101702332496643),\n",
              " ('happened', 0.2837221920490265),\n",
              " ('so', 0.26725488901138306),\n",
              " ('arabic', 0.24304452538490295),\n",
              " ('geometry', 0.23574993014335632),\n",
              " ('development', 0.2188211977481842),\n",
              " ('mathematics', 0.21244122087955475),\n",
              " ('before', 0.21158958971500397),\n",
              " ('ideas', 0.2111380249261856)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiOcBmFFLZHC",
        "outputId": "fea3bd9c-5400-43de-cd2e-945c82bbba4a"
      },
      "source": [
        "model.similarity(\"important\", \"mathematics\") ##find similarity between two words"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21244122"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0smNMhnLlqx",
        "outputId": "10955241-8219-48bc-e74f-2a5a92125acc"
      },
      "source": [
        "model.similar_by_word(\"one\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('much', 0.33913201093673706),\n",
              " ('alkhwarizmi', 0.32167887687683105),\n",
              " ('aspect', 0.3167042136192322),\n",
              " ('geometrical', 0.2614997625350952),\n",
              " ('allowed', 0.2572377920150757),\n",
              " ('applied', 0.251812219619751),\n",
              " ('be', 0.25068730115890503),\n",
              " ('move', 0.2405657023191452),\n",
              " ('the', 0.23903129994869232),\n",
              " ('beginnings', 0.23830656707286835)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GreBbmmqL1PR"
      },
      "source": [
        "**Using CountVectorizer **\n",
        "Dictionary of Word Frequency\n",
        "*texte en italique*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "1eRMzW66MDHB",
        "outputId": "b06a80cc-714a-4ee3-a30f-1e4cc5a7f7d9"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "  \n",
        " \n",
        "count_vec = CountVectorizer(ngram_range=(1,1),stop_words='english')\n",
        "count_data = count_vec.fit_transform([dataset[0]])\n",
        "print(count_vec.get_feature_names())\n",
        "my_df=pd.DataFrame(count_data.toarray(),columns=count_vec.get_feature_names()).T\n",
        "my_df.head(10)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['advances', 'al', 'algebra', 'algebraic', 'allowed', 'applied', 'arabic', 'aspect', 'away', 'began', 'beginnings', 'broader', 'concept', 'development', 'essentially', 'existed', 'future', 'gave', 'geometrical', 'geometry', 'greek', 'happened', 'idea', 'ideas', 'important', 'introduction', 'irrational', 'just', 'khwarizmi', 'magnitudes', 'mathematics', 'new', 'numbers', 'objects', 'path', 'provided', 'rational', 'revolutionary', 'significant', 'subject', 'theory', 'time', 'treated', 'understand', 'unifying', 'vehicle', 'way', 'work']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>advances</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>al</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>algebra</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>algebraic</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>allowed</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>applied</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arabic</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aspect</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>began</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0\n",
              "advances   1\n",
              "al         1\n",
              "algebra    2\n",
              "algebraic  2\n",
              "allowed    2\n",
              "applied    1\n",
              "arabic     1\n",
              "aspect     1\n",
              "away       1\n",
              "began      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVPAqFq4NlNS",
        "outputId": "0e6c4974-7cb4-4b4e-f80b-f6af47327f24"
      },
      "source": [
        "[ ]\n",
        "unt_vec=CountVectorizer(token_pattern=r\"(?u)\\b\\w\\w+\\b\")\n",
        "arr = count_vec.fit_transform([dataset[1]]).toarray()\n",
        "print(arr)\n",
        "print('\\nvocabulary list:\\n')\n",
        "for key,value in count_vec.vocabulary_.items():\n",
        "    print(key,value)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 1 1 1 1 1 1 1 1 2 1 3 2 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 3 1 2 1 3 1 1 1 1 1 1 1 1 1 1 3 1 1 1\n",
            "  1 1 1 2 1 1 1 1 1 1 1 1 1]]\n",
            "\n",
            "vocabulary list:\n",
            "\n",
            "ربما 46\n",
            "كانت 57\n",
            "أحد 2\n",
            "أهم 8\n",
            "التطورات 11\n",
            "التي 12\n",
            "قامت 54\n",
            "بها 36\n",
            "الرياضيات 18\n",
            "العربية 19\n",
            "بدأت 30\n",
            "في 53\n",
            "هذا 75\n",
            "الوقت 27\n",
            "بعمل 33\n",
            "الخوارزمي 16\n",
            "وهي 84\n",
            "بدايات 31\n",
            "الجبر 13\n",
            "ومن 83\n",
            "المهم 24\n",
            "فهم 52\n",
            "كيف 60\n",
            "هذه 76\n",
            "الفكرة 20\n",
            "الجديدة 15\n",
            "مهمة 70\n",
            "فقد 51\n",
            "خطوة 45\n",
            "ثورية 40\n",
            "بعيدا 34\n",
            "عن 49\n",
            "المفهوم 23\n",
            "اليوناني 28\n",
            "للرياضيات 64\n",
            "هي 79\n",
            "جوهرها 44\n",
            "هندسة 77\n",
            "الجبركان 14\n",
            "نظرية 73\n",
            "موحدة 72\n",
            "تتحيح 37\n",
            "الأعداد 10\n",
            "الكسرية 21\n",
            "اللا 22\n",
            "كسرية 58\n",
            "والمقادير 80\n",
            "الهندسية 26\n",
            "غيرها 50\n",
            "أن 5\n",
            "تتعامل 38\n",
            "على 48\n",
            "أنها 7\n",
            "أجسام 1\n",
            "جبرية 42\n",
            "أعطت 3\n",
            "ككل 59\n",
            "مسارا 66\n",
            "جديد 43\n",
            "للتطوربمفهوم 62\n",
            "أوسع 9\n",
            "بكثير 35\n",
            "من 68\n",
            "الذي 17\n",
            "كان 56\n",
            "موجود 71\n",
            "قبل 55\n",
            "وقدم 82\n",
            "وسيلة 81\n",
            "للتنمية 63\n",
            "الموضوع 25\n",
            "مستقبلا 67\n",
            "جانب 41\n",
            "آخر 0\n",
            "مهم 69\n",
            "لإدخال 61\n",
            "أفكار 4\n",
            "هو 78\n",
            "أنه 6\n",
            "سمح 47\n",
            "بتطبيق 29\n",
            "نفسها 74\n",
            "بطريقة 32\n",
            "لم 65\n",
            "تحدث 39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q757Kfr1OZfK",
        "outputId": "14408b5a-4a11-441d-eed6-c7f7f116b2ef"
      },
      "source": [
        "print(count_data)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 38)\t2\n",
            "  (0, 0)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 30)\t4\n",
            "  (0, 9)\t1\n",
            "  (0, 41)\t1\n",
            "  (0, 47)\t1\n",
            "  (0, 1)\t1\n",
            "  (0, 28)\t1\n",
            "  (0, 10)\t1\n",
            "  (0, 2)\t2\n",
            "  (0, 24)\t2\n",
            "  (0, 43)\t1\n",
            "  (0, 27)\t1\n",
            "  (0, 31)\t2\n",
            "  (0, 22)\t1\n",
            "  (0, 37)\t1\n",
            "  (0, 8)\t1\n",
            "  (0, 20)\t1\n",
            "  (0, 12)\t2\n",
            "  (0, 14)\t1\n",
            "  (0, 19)\t1\n",
            "  (0, 44)\t1\n",
            "  (0, 40)\t1\n",
            "  (0, 4)\t2\n",
            "  (0, 36)\t1\n",
            "  (0, 32)\t2\n",
            "  (0, 26)\t1\n",
            "  (0, 18)\t1\n",
            "  (0, 29)\t1\n",
            "  (0, 42)\t1\n",
            "  (0, 3)\t2\n",
            "  (0, 33)\t1\n",
            "  (0, 17)\t1\n",
            "  (0, 13)\t2\n",
            "  (0, 34)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 15)\t1\n",
            "  (0, 35)\t1\n",
            "  (0, 45)\t1\n",
            "  (0, 16)\t1\n",
            "  (0, 39)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 25)\t1\n",
            "  (0, 23)\t1\n",
            "  (0, 5)\t1\n",
            "  (0, 46)\t1\n",
            "  (0, 21)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-owQx9YJOe7n"
      },
      "source": [
        "**TfidfVectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "TP1etl8lOghQ",
        "outputId": "fd67f486-bcb6-45c0-8e7c-20e6c55a0af0"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        " \n",
        "#define tf-idf\n",
        "tf_idf_vec = TfidfVectorizer(use_idf=True, \n",
        "                        smooth_idf=False,  \n",
        "                        ngram_range=(1,1),stop_words='english')\n",
        "#transform\n",
        "tf_idf_data = tf_idf_vec.fit_transform([dataset[0]])\n",
        " \n",
        "#create dataframe\n",
        "tf_idf_dataframe=pd.DataFrame(tf_idf_data.toarray(),columns=tf_idf_vec.get_feature_names()).T\n",
        "tf_idf_dataframe.head(10)\n",
        " "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>advances</th>\n",
              "      <td>0.105409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>al</th>\n",
              "      <td>0.105409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>algebra</th>\n",
              "      <td>0.210819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>algebraic</th>\n",
              "      <td>0.210819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>allowed</th>\n",
              "      <td>0.210819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>applied</th>\n",
              "      <td>0.105409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arabic</th>\n",
              "      <td>0.105409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aspect</th>\n",
              "      <td>0.105409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away</th>\n",
              "      <td>0.105409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>began</th>\n",
              "      <td>0.105409</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "advances   0.105409\n",
              "al         0.105409\n",
              "algebra    0.210819\n",
              "algebraic  0.210819\n",
              "allowed    0.210819\n",
              "applied    0.105409\n",
              "arabic     0.105409\n",
              "aspect     0.105409\n",
              "away       0.105409\n",
              "began      0.105409"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e3CMaJ9Or5g"
      },
      "source": [
        "**Continuous Bag of Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "Rp7eE9PKOvMn",
        "outputId": "a8495ccf-de99-4088-dcb4-63d91022bbaf"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "model = Tokenizer() ## init tokenizer\n",
        "model.fit_on_texts(dataset[0]) ## change this data[0] to 1 if you want insert arabic text\n",
        "print(f'Key : {list(model.word_index.keys())}') # Print Keys \n",
        "\n",
        "\n",
        "\n",
        "# summarize what was learned\n",
        "print(model.word_counts)\n",
        "print(model.document_count)\n",
        "print(model.word_index)\n",
        "print(model.word_docs)\n",
        "\n",
        "\n",
        "#create bag of words representation \n",
        "text_to_vector = model.texts_to_matrix(dataset[0], mode='count')\n",
        "my_cbow_result = pd.DataFrame(text_to_vector)\n",
        "my_cbow_result"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Key : ['e', 'a', 't', 'i', 'o', 'n', 'h', 'r', 's', 'c', 'm', 'l', 'd', 'w', 'b', 'f', 'p', 'g', 'u', 'y', 'v', 'k', 'j', 'z', 'x']\n",
            "OrderedDict([('p', 15), ('e', 77), ('r', 33), ('h', 35), ('a', 72), ('s', 33), ('o', 45), ('n', 38), ('f', 16), ('t', 67), ('m', 25), ('i', 52), ('g', 15), ('c', 26), ('d', 22), ('v', 8), ('b', 17), ('y', 9), ('w', 20), ('k', 3), ('l', 24), ('z', 1), ('u', 12), ('j', 3), ('x', 1)])\n",
            "814\n",
            "{'e': 1, 'a': 2, 't': 3, 'i': 4, 'o': 5, 'n': 6, 'h': 7, 'r': 8, 's': 9, 'c': 10, 'm': 11, 'l': 12, 'd': 13, 'w': 14, 'b': 15, 'f': 16, 'p': 17, 'g': 18, 'u': 19, 'y': 20, 'v': 21, 'k': 22, 'j': 23, 'z': 24, 'x': 25}\n",
            "defaultdict(<class 'int'>, {'p': 15, 'e': 77, 'r': 33, 'h': 35, 'a': 72, 's': 33, 'o': 45, 'n': 38, 'f': 16, 't': 67, 'm': 25, 'i': 52, 'g': 15, 'c': 26, 'd': 22, 'v': 8, 'b': 17, 'y': 9, 'w': 20, 'k': 3, 'l': 24, 'z': 1, 'u': 12, 'j': 3, 'x': 1})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>809</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>810</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>811</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>812</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>813</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>814 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1    2    3    4    5    6   ...   19   20   21   22   23   24   25\n",
              "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "1    0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4    0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "809  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "810  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "811  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "812  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "813  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[814 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z6Y1RTzO7rA"
      },
      "source": [
        "**sklearn.preprocessing.OneHotEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1GADkRXO-P5",
        "outputId": "8c2fb1cc-7283-4e20-f147-e0214a3b2322"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "values = np.array(tokenized_list)\n",
        "print(values)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "my_int_encoded = label_encoder.fit_transform(values)\n",
        "print(my_int_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "my_int_encoded = my_int_encoded.reshape(len(my_int_encoded), 1)\n",
        "onehot_encoded_values = onehot_encoder.fit_transform(my_int_encoded)\n",
        "print(onehot_encoded_values)\n",
        "inverted_values = label_encoder.inverse_transform([np.argmax(onehot_encoded_values[0, :])])\n",
        "print(inverted_values)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['perhaps' 'one' 'of' 'the' 'most' 'significant' 'advances' 'made' 'by'\n",
            " 'arabic' 'mathematics' 'began' 'at' 'this' 'time' 'with' 'the' 'work'\n",
            " 'of' 'alkhwarizmi' 'namely' 'the' 'beginnings' 'of' 'algebra' 'it' 'is'\n",
            " 'important' 'to' 'understand' 'just' 'how' 'significant' 'this' 'new'\n",
            " 'idea' 'was' 'it' 'was' 'a' 'revolutionary' 'move' 'away' 'from' 'the'\n",
            " 'greek' 'concept' 'of' 'mathematics' 'which' 'was' 'essentially'\n",
            " 'geometry' 'algebra' 'was' 'a' 'unifying' 'theory' 'which' 'allowed'\n",
            " 'rational' 'numbers' 'irrational' 'numbers' 'geometrical' 'magnitudes'\n",
            " 'etc' 'to' 'all' 'be' 'treated' 'as' 'algebraic' 'objects' 'it' 'gave'\n",
            " 'mathematics' 'a' 'whole' 'new' 'development' 'path' 'so' 'much'\n",
            " 'broader' 'in' 'concept' 'to' 'that' 'which' 'had' 'existed' 'before'\n",
            " 'and' 'provided' 'a' 'vehicle' 'for' 'future' 'development' 'of' 'the'\n",
            " 'subject' 'another' 'important' 'aspect' 'of' 'the' 'introduction' 'of'\n",
            " 'algebraic' 'ideas' 'was' 'that' 'it' 'allowed' 'mathematics' 'to' 'be'\n",
            " 'applied' 'to' 'itself' 'in' 'a' 'way' 'which' 'had' 'not' 'happened'\n",
            " 'before']\n",
            "[60 58 57 68 49 64  1 46 20 10 48 17 13 70 71 81 68 82 57  4 52 68 18 57\n",
            "  2 43 42 38 72 74 45 35 64 70 53 36 77 43 77  0 63 50 14 27 68 32 21 57\n",
            " 48 79 77 23 31  2 77  0 75 69 79  6 62 55 41 55 30 47 24 72  5 15 73 11\n",
            "  3 56 43 29 48  0 80 53 22 59 65 51 19 39 21 72 67 79 33 25 16  7 61  0\n",
            " 76 26 28 22 57 68 66  8 38 12 57 68 40 57  3 37 77 67 43  6 48 72 15  9\n",
            " 72 44 39  0 78 79 33 54 34 16]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "['perhaps']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ysxr6e32PDSq",
        "outputId": "e92fafc9-20ef-445f-e160-5e36df108fe3"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "# define the document\n",
        "words = set(text_to_word_sequence(dataset[0]))\n",
        "vocab_size = len(words)\n",
        "print(vocab_size)\n",
        "# integer encode the document\n",
        "result = one_hot(dataset[0], round(vocab_size))\n",
        "print(result)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84\n",
            "[38, 35, 63, 23, 37, 81, 24, 60, 42, 74, 74, 78, 38, 4, 28, 49, 23, 16, 63, 18, 61, 34, 23, 13, 63, 80, 14, 61, 51, 72, 18, 13, 25, 81, 4, 48, 30, 44, 14, 44, 56, 50, 67, 39, 1, 23, 70, 2, 63, 74, 3, 44, 64, 57, 80, 44, 56, 46, 34, 3, 76, 12, 83, 63, 83, 56, 50, 62, 72, 35, 66, 71, 66, 77, 4, 14, 47, 74, 56, 82, 48, 31, 34, 71, 62, 62, 33, 2, 72, 63, 3, 71, 22, 50, 60, 59, 56, 48, 62, 33, 31, 63, 23, 51, 75, 51, 12, 63, 23, 79, 63, 77, 69, 44, 63, 14, 76, 74, 72, 66, 6, 72, 53, 33, 56, 40, 3, 71, 23, 78, 50]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}